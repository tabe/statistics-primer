#+TITLE: ベイズ統計入門
#+AUTHOR: 安部武志
#+EMAIL: t.abe@yamaguchi-u.ac.jp
#+DATE: 2022-06-15
#+OPTIONS: email:t toc:nil
#+LICENSE: CC BY-SA 4.0
#+LATEX_COMPILER: lualatex
#+LATEX_CLASS: ltjsarticle
#+LATEX_HEADER: \usepackage[type={CC},modifier={by-sa},version={4.0}]{doclicense}
#+LATEX_HEADER: \input{definitions.tex}

* この文書について

この文書[fn:1]では、確率や統計の初学者を対象に、ベイズ統計の考え方を説明する。

* 確率に関する表記

** 慣習
この入門では、よく見られる確率論の慣習に従った表記に従う。
- 別途明示的に書かない限り、各確率変数は確率空間\((\Omega, \Field, \mathbb{P})\)上のものとする。
  ここで\(\Omega\)は標本空間、\(\Field\)は事象全体の集合(つまり\(\Omega\)上の完全加法族)、\(\mathbb{P}\)は確率関数である。
- 事象\(A\)について、\(\Prob{A}\)は\(A\)の確率を表す。
- 確率変数\(X\)について、ある実現値の(可測)集合\(W\)から定まる事象\(X^{-1}(W)\)[fn:2]についての確率\(\Prob{X^{-1}(W)}\)を\(\Prob{X \in W}\)と略す。
- 確率変数\(X\)に対して\(\Prob{X}\)と書くことがあるが、これは"\(\Prob{X \in W}\)"のうちの"\(\in W\)"を略しているため、具体的な確率ではなく任意の(可測)集合\(W\)についての言明で用いられる。
- 離散確率変数の場合には、確率\(\Prob{X \in \{x\}}\)を\(\Prob{X = x}\)で表す。
  さらには\(X\)も略して、\(\Prob{x}\)と書くこともある。
  実現値をアルファベットの小文字で表しているために、かろうじて\(\Prob{X}\)と区別できる。
- 中には、確率\(\Prob{X \in W}\)を\(\Prob{W}\)と書いてしまう略記もある。
  \(W\)がある実現値の集合であり、結果の集合ではないということが明確で混乱がなければこれも許される。
  が、初学者には親切とはいえない。
- \(\CondProb{A}{B}\)は、事象\(A\)という前提の下での事象\(B\)の条件付き確率を表す。
  条件付きでない確率の場合と同じように、しばしば\(\CondProb{x}{y}\)のように略記する。

** 独自の配慮
記号を見ただけで何を表すかが分かりやすいように、この入門では以下のような表記を用いる。
- 確率変数を表す記号: \(X, X_i\)等
- 事象を表す記号: \(A, B, A_i, B_i\)等
- 実現値を表す記号: \(x, x_i\)等
- 実現値の(可測)集合を表す記号: \(W, W_i\)等
- 母数を表す記号: \(\theta\)等

** その他の記法
- \(\Reals^+ \equiv \{r \in \Reals: r \geq 0\}\): 非負実数集合

* 推計統計のための数理
推計統計の2つの流儀である頻度主義統計およびベイズ統計は、以下の図に示すような共通の数学的な基礎づけがされている。
#+begin_export latex
\input{foundation.tex}
#+end_export

* 確率論の基本
** 独立性
任意の事象\(A\)および\(B\)について、\(A\)と\(B\)が独立であるとは以下の条件が成り立つことである。
#+begin_export latex
\begin{equation}\label{eqn:independence1}
\Prob{A \cap B} = \Prob{A} \Prob{B}
\end{equation}
#+end_export
ただし\(A \cap B\)は\(A\)と\(B\)の[[https://en.wikipedia.org/wiki/Intersection_(set_theory)][共通部分]]を表し、\(A\)かつ\(B\)が生じているという事象を表す。

独立性は、2つの確率変数\(X\)と\(Y\)の間にも自然に拡張して定義される。
共通の確率空間上の確率変数\(X\)および\(Y\)について、\(X\)と\(Y\)が独立であるとは以下の条件が成り立つことである。
#+begin_export latex
\begin{equation}\label{eqn:independence2}
\Prob{X, Y} = \Prob{X} \Prob{Y}
\end{equation}
#+end_export
ただし\(\Prob{X, Y}\)は\(X\)と\(Y\)の同時確率を表す。

** 条件付き確率
任意の事象\(A\)および\(B\)について、条件付き確率\(\CondProb{A}{B}\)は以下のように定義される。
#+begin_export latex
\begin{equation}\label{eqn:conditional}
\CondProb{A}{B} \equiv \frac{\Prob{A \cap B}}{\Prob{B}}
\end{equation}
#+end_export

式(\ref{eqn:conditional})から分かるように、条件付き確率\(\CondProb{A}{B}\)は\(B\)が生じたという条件の下で\(A\)が生じる確率を表し、\(\Prob{B} \neq 0\)であるときのみ定義される。

定義から、\(A\)と\(B\)が独立であるときは
\[
\CondProb{A}{B} = \Prob{A}
\]
かつ
\[
\CondProb{B}{A} = \Prob{B}
\]
が成り立つ。

** ベイズの定理
条件付き確率について成り立つ以下の事実は、「ベイズの定理」と呼ばれる確率論の基本的な定理である。

任意の事象\(A\)および\(B\)について、\(\Prob{A} \neq 0\)のとき[fn:3]以下が成り立つ:
#+begin_export latex
\begin{equation}\label{eqn:theorem}
\CondProb{A}{B} = \frac{\CondProb{B}{A} \Prob{A}}{\Prob{B}}
\end{equation}
#+end_export

この定理にしたがって事前確率とデータから事後確率を求めるというのが、ベイズ統計の基本となるアイデアである[fn:4]。

** 尤度
前節の式(\ref{eqn:theorem})から、興味の対象である仮説を\(H\)という確率変数で表すものとし、データを表す確率変数を\(D\)とするとき、
\[\Prob{H \mid D} = \frac{\Prob{D \mid H} \Prob{H}}{\Prob{D}}\]
と表される。

あるいは、仮説を表現するモデルに母数\(\theta\)という確率変数を用いる場合には、以下のようになる。
\[\Prob{\theta \mid D} = \frac{\Prob{D \mid \theta} \Prob{\theta}}{\Prob{D}}\]

上式のうち、\(\Prob{D \mid \theta}\)という条件付き確率を尤度と呼ぶ。

* 最尤法

異なるいくつかの仮説から、与えられたデータに対し尤度を最大にするような仮説を選ぶ(推定する)ことを最尤法による推定、または最尤法と呼ぶ。
すなわち
\[
\ML{H} = \argmax_{H} \CondProb{D}{H}
\]
を満たす\(\ML{H}\)を選ぶ。

同様に、仮説を表現するために母数\(\theta\)で定まるモデルを用いる場合には、最尤推定では以下のように\(\ML{\theta}\)を選ぶ。
#+begin_export latex
\begin{equation}\label{eqn:maximum-likelihood}
\ML{\theta} = \argmax_{\theta \in \Theta} \CondProb{D}{\theta}
\end{equation}
#+end_export

* ベイズ統計の概要
ベイズ統計の枠組みを簡単に図示すると、以下のようになる:

#+begin_export latex
\input{bayesian-framework.tex}
#+end_export

真ん中の箱のようなものがベイズ統計で行う「推定」を表し、事後分布とデータが「入力」、事後分布が「出力」であることを表す。

* 頻度主義統計とベイズ統計の比較
** 共通点
頻度主義統計とベイズ統計という2つの流儀を比べるために、まず何が共通なのかについて述べる。
- どちらの流儀でも確率変数でランダムな出来事を表すという点は同じである。

** 相違点
頻度主義統計においては、対象となる仮説が真であるかそうでないかのどちらかを判断するために推論する。
一方ベイズ統計においては、仮説が真であるかどうかの不確かさを確率変数として表す。
このことは、パラメトリックモデルの母数に依存して仮説の真偽が決まる場合には次のように言い換えられる。

- 頻度主義統計におけるパラメトリックモデルでは、その確率分布の母数は(未知の)固定された値をもつとされる。
- 一方、ベイズ統計におけるパラメトリックモデルでは、その母数自体の不確かさを(別途)確率変数で表す。

** 対照的な点についての一覧
以下に頻度主義統計とベイズ統計という2つの流儀を比較した表を示す。

|      | 頻度主義統計                       | ベイズ統計                             |
|------+------------------------------------+----------------------------------------|
| 標本 | ランダム                           | ランダム                               |
| 母数 | 固定                               | ランダム                               |
| 前提 | 標本分布が既知である               | 事前分布を考える                       |
| 目標 | 仮説や母数についての言明を判断する | 仮説や母数についての事後分布を推定する |
| 基準 | 最尤法                             | MAP法                                  |

この入門では以降で順にこれらの相違点について説明する。

* (意思)決定理論
決定理論と呼ばれる理論は、確率論に基づいた数学の一分野である。
ランダムな出来事に影響されるような状況における意思決定で、いかに損失を少なくするかという問題を解くための理論である。
つまり、確率変数に依存する損失をなるべく小さくすることを目的としている。

#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\node[draw,circle] (theta) at (0,0) {母数};
\node[draw,rectangle,inner sep=5mm] (X) at (2,0) {\(X: \Outcome \to \Realization\)};
\node[draw,circle] (x) at (4,0) {\(x\)};
\node[draw,rectangle,inner sep=5mm] (d) at (4,-2) {\(d: \Realization \to \Action\)};
\node[draw,circle] (a) at (6,-2) {\(a\)};
\node[draw,rectangle,inner sep=5mm] (loss) at (6,-4) {\(L: \Theta \times \Action \to \Reals\)};

\draw (theta) -- (X);
\draw[->] (X) -- (x);
\draw[->] (x) -- (d);
\draw[->] (d) -- (a);
\draw[->] (theta) |- (loss);
\draw[->] (a) -- (loss);
\end{tikzpicture}
\caption{決定理論の枠組み}
\end{figure}
#+end_export

* 観察された実現値と行為
ランダムな出来事を確率空間\((\Outcome, \Field, P)\)上の確率変数\(X: \Outcome \to \Realization\)で表現する。
とり得る行為は一般に複数あり、それら全体の集合を\(\Action\)で表す。
観察した実現値\(x\)に応じて\(\Action\)の中から1つを選ぶ(決定する)とする。

さまざまな意思決定の状況をこの形式に当てはめることができる。以下にいくつかの例を挙げる。

#+begin_export latex
\newcommand{\exampleI}[1]{
\begin{itemize}
\item \(\Theta = \{健康, 睡眠不足, 風邪, インフルエンザ, \text{SARS-CoV-2}, ...\}\): 朝の身体状態
\item \(\Realization = \Reals\): 朝の体温(℃)
\item \(\Action = \{登校する, 休む, 病院に行く, ...\}\)
#1
\end{itemize}
}
\newcommand{\exampleII}[1]{
\begin{itemize}
\item \(\Theta = \Reals^+\): 今日の24時間降水量(mm)
\item \(\Realization = \Reals^+\): 午前8時時点の1時間降水量(mm)
\item \(\Action = \{傘を持たずに出かける, 傘を持って出かける, 外出しない, 避難する, ...\}\)
#1
\end{itemize}
}
\newcommand{\exampleIII}[1]{
6面体サイコロが1つ与えられる。
\begin{itemize}
\item \(\Theta = [0, 1]^6\): あるサイコロの出目の分布を表すcategorical distributionの母数
\item \(\Realization = \{1,2,3,4,5,6\}^n\): そのサイコロを\(n\)回独立に振った場合の出目を表す長さ\(n\)の列
\item \(\Action = [1, 6]\): そのサイコロの出目の平均の点推定
#1
\end{itemize}
}
\newcommand{\exampleIV}[1]{
6面体サイコロが1つ与えられる。
\begin{itemize}
\item \(\Theta = [0, 1]^6\): そのサイコロの出目の分布を表すcategorical distributionの母数
\item \(\Realization = \{1,2,3,4,5,6\}^n\): そのサイコロを\(n\)回独立に振った場合の出目を表す長さ\(n\)の列
\item \(\Action = [1, 6]^2\): そのサイコロの出目の平均の95\%信頼区間
#1
\end{itemize}
}
\newcommand{\exampleV}[1]{
クローンヒツジが\(n\)匹ずつ2群いる。各群のヒツジはそれぞれオリジナルのヒツジaおよびヒツジbからのクローンである。
\begin{itemize}
\item \(\Theta = \{\theta_0("aはbと同じである"), \theta_1("aとbは異なる")\}\)
\item \(\Realization = (\Reals^+)^{2n}\): n匹ずつ2つの群に分かれている各ヒツジの体重(kg)
\item \(\Action = \{H_0("2群は同じ母集団に属する"), H_1("2群は同じ母集団に属しない")\}\): 仮説
#1
\end{itemize}
}
\newcommand{\exampleVI}[1]{
確率変数\(X\)と線形関係にある別の確率変数\(Y\)の組について、\(n\)個の実現値を独立に観測する。
\begin{itemize}
\item \(\Theta = \Reals\): \(Y = \epsilon + \alpha X\)を満たす\(\alpha\)、ただし\(\epsilon\)は誤差
\item \(\Realization = (\Reals^2)^n\): 2次元平面上の\(n\)個の点\((x_i, y_i)\)
\item \(\Action = \Reals\): \(y_i = a x_i\)に対して最小二乗法で求めた\(a\)
#1
\end{itemize}
}
#+end_export

** 意思決定の例1
#+begin_export latex
\exampleI{}
#+end_export

** 意思決定の例2
#+begin_export latex
\exampleII{}
#+end_export

** 意思決定の例3
#+begin_export latex
\exampleIII{}
#+end_export

** 意思決定の例4
#+begin_export latex
\exampleIV{}
#+end_export

** 意思決定の例5
#+begin_export latex
\exampleV{}
#+end_export

** 意思決定の例6
#+begin_export latex
\exampleVI{}
#+end_export

このように、点推定、区間推定、仮説検定、そして回帰も意思決定問題として形式化できる。

* 損失関数、あるいは効用関数
損失関数を最小にするという問題は、負の符号をほどこした対応する効用関数を最大にするという問題に置き換えることができる。
逆もまた可能である。なので、一方を考えることは他方を考えることと同じである。
以後この入門では、損失関数を考えることを前提とする。

損失関数は母数と行為を引数にもつ実数値関数である:
\[
L: \Theta \times \Action \to \Reals
\]
ここで\(\Theta \times \Action\)は\(\Theta\)と\(\Action\)の[[https://en.wikipedia.org/wiki/Cartesian_product][直積]]を表す。

損失関数\(L\)について、この入門では常に
\[
L(\theta, a) \geq 0
\]
が成り立つものとする。これは本質的な制限ではないが、後の議論を容易にする。

確率変数を引数にもつ損失関数は、それ自体が確率変数になる。
したがって、適切な条件の下で期待値をもつ。

* 決定規則
各実現値についてどのような行為を選ぶかについての取り決めが決定規則である。
決定規則を定めることは、可能な実現値全体の集合である\(\Realization\)から可能な行為全体の集合である\(\Action\)への関数を定めることである。
つまり、ある決定規則\(d\)は
\[d: \Realization \to \Action\]
という関数で表される。
決定理論では、個別の決定規則について損失がどのくらいになるかを評価し、損失が少ないものを選ぶことに腐心する。

この入門では単に規則と略すことにする。

* 意思決定の模式化
(意思)決定理論における意思決定の枠組みを図\ref{fig:decision-scheme}に示す。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\decisionscheme{a}
\end{tikzpicture}
\caption{意思決定の枠組み} \label{fig:decision-scheme}
\end{figure}
#+end_export

** 頻度主義統計による決定
上述の意思決定の枠組みで有意性検定や仮説検定といった頻度主義統計での意思決定を模式化すると、図\ref{fig:frequentist-scheme}のようになる。
図\ref{fig:decision-scheme}と比較すると、\(\Omega\)や\(\mathcal{X}\)の代わりに\(\Psi\)や\(\mathcal{S}\)が出てきているが、
同じ枠組みで扱えることが分かる。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\input{frequentist-scheme.tex}
\end{tikzpicture}
\caption{頻度主義統計での意思決定の枠組み} \label{fig:frequentist-scheme}
\end{figure}
#+end_export
頻度主義統計でも不確かさを含む出来事を確率変数\(X\)で表し、特にパラメトリックな場合にはその母数\(\theta\)について判断しようとする。
しかし、実際にデータとして用いるのは\(X\)からの\(n\)個の独立な標本であり、意思決定は標本分布に従う別の確率変数\(S\)を通じて行われる。
一般に、この標本分布は標本サイズ\(n\)に依存している。
同時に、この\(S\)は\(\theta\)に依存しており、間接的な形であるが\(X\)について判断できることになる。

例えば、母平均\(\mu\)を点推定するために標本平均\(\bar{x}\)を用いることは、図\ref{fig:frequentist-scheme}内の\(s\)として
\[
s = \bar{x} = \frac{\sum_{i=1}^n x_i}{n}
\]
という統計量を考えていることになる。

* リスク
損失関数\(L\)が与えられ、母数の値が\(\theta \in \Theta\)である場合、リスク関数\(\Risk(\theta, d)\)は次のように定義される:
\[
\Risk(\theta, d) = \Esub{\theta}{L(\theta, d(X))}
\]
すなわち、リスクは決定規則\(d\)を選んだときの期待損失のことである。
ここで
- \(\Esub{\theta}{\cdot}\)が母数の値が\(\theta\)である分布に関する期待値であること、および
- \(\Risk(\theta, d) \geq 0\)であること
に注意。

* 好ましい決定規則の種類
ランダムな出来事が結果に影響するような状況では、どのようにリスクを小さくするかについていろいろなアプローチがあり得る。
ここでは、2通りの好ましい規則について説明する。

** ミニマックス規則
下した意思決定が招く最大のリスクをできるだけ小さくしたいとする。
このようなときに求めるのは、次の性質を満たすような規則\(d^\ast\)である: すべての規則\(d\)について
#+begin_export latex
\begin{equation}\label{eqn:minimax}
\MaxRisk(d^\ast) \leq \MaxRisk(d).
\end{equation}
#+end_export
ただし
\[
\MaxRisk(d) \equiv \sup_{\theta \in \Theta} R(\theta, d)
\]
と定義する。
つまり、他の規則に変えてもリスクの上限がこれより小さくならないような規則が\(d^\ast\)である。
上の式(\ref{eqn:minimax})を満たす規則\(d^\ast\)をミニマックス(リスク)規則と呼ぶ。

ミニマックス規則\(d^\ast\)があれば、\(\MaxRisk(d^\ast)\)は
\[
\inf_{d \in \D} \sup_{\theta \in \Theta} R(\theta, d)
\]
と一致する。
さらに実際に上限\(\sup_{\theta \in \Theta}\)を達成する値\(\theta\)があるときは、上を
\[
\min_{d \in \D} \max_{\theta \in \Theta} \Risk(\theta, d)
\]
と表してもよく、ミニマックスと呼ばれる所以である。

** もし母数自体が確率変数なら
もし母数\(\theta\)の不確かさを確率変数として考える場合には、図\ref{fig:theta-is-random}のように拡張される。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\input{bayesian-scheme.tex}
\end{tikzpicture}
\caption{母数を確率変数と見なす場合の意思決定} \label{fig:theta-is-random}
\end{figure}
#+end_export

** ベイズ規則
仮に母数\(\theta\)が確率変数とする。
このとき\(R(\theta, d)\)も確率変数となる。
適切な条件の下で、次のような期待値が定まる。
\[
\BayesRisk(d) \equiv \E{R(\theta, d)}
\]
この期待リスクをできるだけ小さくしたいとする。
そのようなときに求める規則\(d^\star\)は、次の性質を満たす: すべての規則\(d\)について
#+begin_export latex
\begin{equation}\label{eqn:bayesian}
\BayesRisk(d^\star) \leq \BayesRisk(d).
\end{equation}
#+end_export
つまり、他の規則に変えても期待リスクがこれより小さくならないような規則が\(d^\star\)である。
上の式(\ref{eqn:bayesian})を満たす規則\(d^\star\)をベイズ規則と呼ぶ。

* ベイズ統計による決定
ベイズ統計では、ベイズ規則に従って事後分布\(\thetaposterior\)を求める。
つまり、行為として\(\thetaposterior\)を決定する。
事前分布\(\thetaprior\)から事後分布\(\thetaposterior\)に至るベイズ統計での意思決定を模式化すると、図\ref{fig:bayesian-scheme2}のようになる。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\input{bayesian-scheme2.tex}
\end{tikzpicture}
\caption{ベイズ統計での意思決定の枠組み} \label{fig:bayesian-scheme2}
\end{figure}
#+end_export

* パラメトリックなベイズ推定
ベイズ統計の模式図\ref{fig:bayesian-framework}は、パラメトリックなモデルの場合は図\ref{fig:parametric-bayesian-framework}のようになる。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\node[draw,rectangle] (box) at (0,0) {推定};
\begin{scope}[every node/.style={draw,circle}]
\node (prior) at (-3,0) {\(\thetaprior\)};
\node (posterior) at (3,0) {\(\thetaposterior\)};
\node (data) at (0,-2) {\(x\)};
\end{scope}
\begin{scope}[every path/.style={-{Latex[open]}}]
\draw (prior) -- (box);
\draw (box) -- (posterior);
\draw (data) -- (box);
\end{scope}
\end{tikzpicture}
\caption{パラメトリックなベイズ推定の模式図} \label{fig:parametric-bayesian-framework}
\end{figure}
#+end_export

* MAP法

異なるいくつかの仮説から、与えられたデータに対し事後確率を最大にするような仮説を選ぶ(推定する)ことをMAP法による推定、またはMAP法と呼ぶ。
すなわち
\[
\MAP{H} = \argmax_{H} \CondProb{H}{D}
\]
を満たす\(\MAP{H}\)を選ぶ。

同様に、仮説を表現するために母数\(\theta\)で定まるモデルを用いる場合には、MAP推定では以下のように\(\MAP{\theta}\)を選ぶ。
#+begin_export latex
\begin{equation}\label{eqn:maximum-a-posteriori}
\MAP{\theta} = \argmax_{\theta \in \Theta} \CondProb{\theta}{D}
\end{equation}
#+end_export

ベイズの定理が適用できる場合、\(\Prob{D}\)は\(\theta\)に依存しないので、式(\ref{eqn:maximum-a-posteriori})は
#+begin_export latex
\begin{equation}\label{eqn:maximum-a-posteriori2}
\MAP{\theta} = \argmax_{\theta \in \Theta} \CondProb{D}{\theta} \Prob{\theta}
\end{equation}
#+end_export
と同じことになる。
最尤推定の式(\ref{eqn:maximum-likelihood})と式(\ref{eqn:maximum-a-posteriori2})を比較すると、\(\theta\)についての事前確率\(\Prob{\theta}\)が現れていることに注意。

* 事前分布の選択
ベイズ統計では、事前分布をどのように決めるかについて、いくつかの典型例がある。
1. 無情報的事前分布
2. パラメトリックなアプローチ
  - 経験的ベイズ
  - 共役事前分布
  - 階層ベイズ
3. ノンパラメトリックなアプローチ
  - 経験的ベイズ
  - ブートストラップ

* 無情報的事前分布
推定対象である確率変数のどの実現値も「同様に確からしい」と考えている場合の事前分布。
- 最尤推定とMAP推定が *一致する*

* 共役事前分布
ベイズ推定に際して事前分布と事後分布が同じ分布族で、\(\thetaprior\)とデータから\(\thetaposterior\)を代数的に容易に求められる場合がある。
このような事前分布を共役事前分布と呼ぶ。

** 共役事前分布の例
\(n\)回試行、成功確率\(p\)の二項分布に従う確率変数\(X\)について推定したい。
- ただし\(n\)は既知で固定とする。\(p\)が未知の母数(\(0 < p < 1\))。

\(p\)の事前分布\(Y\)を、ある\(\alpha > 0\)、\(\beta > 0\)を母数にもつベータ分布で表す。

そのようなベータ分布の密度関数は
\[
f(y; \alpha, \beta) = \frac{y^{\alpha - 1} (1 - y)^{\beta - 1}}{B(\alpha, \beta)},\qquad 0 < y < 1.
\]

\(X\)の観察データ\(x\)が入力された場合の事後分布\(Z\)はやはりベータ分布になり、その密度関数は
\[
f(z \mid x) = \frac{z^{\alpha + x - 1} (1 - z)^{n - x + \beta - 1}}{B(\alpha + x, \beta + n - x)},\qquad 0 < z < 1.
\]

になる。すなわち、\(x\)からすぐ事後分布の母数が計算できる。

|          | 母数                            | 平均                                      | 分散                                                                                    |
|----------+---------------------------------+-------------------------------------------+-----------------------------------------------------------------------------------------|
| 事前分布 | \((\alpha, \beta)\)             | \(\frac{\alpha}{\alpha + \beta}\)         | \(\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}\)                        |
| 事後分布 | \((\alpha + x, \beta + n - x)\) | \(\frac{\alpha + x}{\alpha + \beta + n}\) | \(\frac{(\alpha + x)(\beta + n - x)}{(\alpha + \beta + n)^2 (\alpha + \beta + n + 1)}\) |

* 経験的ベイズ
経験的ベイズでは、標本の *周辺確率* を事前分布に用いる。
特に、事前分布を標本のデータから決める。
これは一見、データと事前分布を分けて考えるベイズ統計の基本にそぐわないように見えるが、実際は後述する階層ベイズの特殊な場合といえる。

* 階層ベイズ
階層ベイズでは、事前分布もまたパラメトリックとして、事前分布の母数を定めるさらなる分布を考える。
すなわち、\(\thetaprior\)自体が\(\xi\)という母数を持つ確率変数とする。
このような\(\xi\)を超母数と呼び、階層ベイズモデルでは\(\xi\)も確率的に振る舞うものとして確率変数\(\xihyperprior\)で表す。

式で書くと
\begin{align*}
\xi &\sim \xihyperprior;\\
\theta \mid \xi &\sim \thetaprior(\xi);\\
x \mid \theta &\sim X_\theta.
\end{align*}

図\ref{fig:hierarchical-bayesian-scheme}のような模式図で表される。
#+begin_export latex
\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\input{hierarchical-bayesian-scheme.tex}
\end{tikzpicture}
\caption{階層ベイズでの意思決定の枠組み} \label{fig:hierarchical-bayesian-scheme}
\end{figure}
#+end_export

さらに階層を増やすこともある。

** 階層ベイズモデルの例: 肉腫の治療効果
Thall et al. (2003)[fn:5]で紹介されている、肉腫に対するimatinibの治療効果についての階層ベイズモデルは次の式で表される。

\(k = 10\)個のサブタイプに対し、それぞれの治療効果\(\rho_i\)は共通の正規分布に従うとする。
\begin{align*}
\mu &\sim \operatorname{Normal}(\mu_{\text{mean}}, \mu_{\text{sd}}^2);\\
\sigma^2 &\sim \operatorname{InverseGamma}(\tau_\alpha, \tau_\beta);\\
\rho_1, \cdots, \rho_k &\sim \operatorname{Normal}(\mu, \sigma^2)
\end{align*}
すなわち、事前分布の母数はベクトル\((\mu, \sigma^2)\)であり、
超母数はベクトル\((\mu_{\text{mean}}, \mu_{\text{sd}}^2, \tau_\alpha, \tau_\beta)\)である。

サブタイプ\(i\)での応答率\(p_i\)は、\(\rho_i\)にlogit関数の逆関数であるlogistic関数をほどこして得られると考え、
サブタイプ\(i\)の\(n_i\)人からなる患者群で\(x_i\)人の応答例が臨床試験で報告されるという状況をモデル化する。
つまり、確率\(p_i\)で成功するベルヌーイ試行を独立に\(n_i\)回した結果の成功回数にあたる二項分布に従う。
\begin{align*}
p_i &= \operatorname{logit}^{-1}(\rho_i) = \operatorname{logistic}(\rho_i) = \frac{1}{1 + e^{-\rho_i}};\\
x_i &\sim \operatorname{Binomial}(n_i, p_i)
\end{align*}

臨床試験の報告データ\(D\)に基づいて治療に効果が期待できるかどうかは、以下のように事後分布から判断できる。
\begin{align*}
\CondProb{p_i > \vartheta}{D} > q
\end{align*}
ただし\(\vartheta\)は考慮に値する応答率の下限、\(q\)は承認に必要な確からしさを表す。
Thall et al. (2003)では、\(\vartheta = 0.3\)とされた。

Rの =trialr= パッケージのドキュメント[fn:6]には、MCMC法による解析例が示されている。

* ブートストラップ法
ブートストラップ法では、限られたサイズの標本から復元抽出で再標本を繰り返すことで、標本分布の情報を得る。

* ナイーブベイズ分類器
与えられたデータから分類器を機械学習する手法の1つ。

ナイーブベイズ分類器は、目的変数\(C\)が与えられたときの各説明変数\(X_i\)同士は独立であるということを前提としている。
すなわち、以下のような条件付き独立性を前提としている。
\[
\CondProb{X_1, X_2, ..., X_N}{C} = \prod_{i=1}^N \CondProb{X_i}{C}
\]

予測される分類
\[
\hat{c} = \argmax_{c \in V_C} \Prob{c} \prod_{i=1}^N \CondProb{x_i}{c}
\]
は、MAP法から導かれる。

* ベイズ統計における区間推定: 信用区間

** 信頼区間と信用区間との対比

|                      | 信頼区間                 | 信用区間                 |
|----------------------+--------------------------+--------------------------|
| 前もって与える水準   | 信頼水準(\(\alpha\)水準) | 幅(\(\delta\))           |
| 標本から導かれるもの | 区間                     | 母数が区間に入る事後確率 |

* 参考文献
この入門を準備する上で、次に挙げる文献を参考にしている。
いずれもさらに学びたいという方にお薦めである。
特に、頻度主義統計とベイズ統計を決定理論という共通の枠組みから扱うというこの入門の骨子は、[1]から拝借している。
[2]は、Rで書かれた具体的なコードで確率分布の振舞いを例示するという現代的な数理統計の教科書である。
経験的ベイズ統計的手法とその応用については[3]が詳しい。
ベイズ統計の基礎とともに数理統計一般を丁寧に説明している教科書として[4]がある。
[5]では、ベイズ統計的手法を用いた生存解析のためのノンパラメトリックおよびセミパラメトリックなモデルを紹介している。
[6]はベイズ統計モデルを用いる際の手順を分かり易い図で示した研究者向けの入門である。
1. Young, G. & Smith, R. (2005). Essentials of Statistical Inference (Cambridge Series in Statistical and Probabilistic Mathematics). Cambridge: Cambridge University Press. [[https://doi.org/10.1017/CBO9780511755392][doi:10.1017/CBO9780511755392]]
2. Chihara, L. M. & Hesterberg, T. C. (2018). Mathematical Statistics with Resampling and R, 2nd Edition. Wiley. ISBN-13: 9781119416548.
3. Efron, B. (2010). Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction, Institute of Mathematical Statistics Monographs. Cambridge University Press, Cambridge. [[https://doi.org/10.1017/CBO9780511761362][doi:10.1017/CBO9780511761362]]
4. Miller, I. & Miller, M. (2018). John E. Freund's Mathematical Statistics with Applications, (Classic Version) 8th Edition (Pearson Modern Classics for Advanced Statistics Series). Pearson. ISBN-13: 9780134995373.
5. Klein, J. P. & Moeschberger, M. L. (2003). Survival Analysis: Techniques for Censored and Truncated Data, 2nd Edition (Statistics for Biology and Health). Springer. [[https://doi.org/10.1007/b97377][doi:10.1007/b97377]]
6. van de Schoot, R., Depaoli, S., King, R. et al. Bayesian statistics and modelling. Nat Rev Methods Primers 1, 1 (2021). [[https://doi.org/10.1038/s43586-020-00001-2][doi:10.1038/s43586-020-00001-2]]

* 用語集
この入門に出てきた統計用語をその英語表記とともにまとめる。
- (意思)決定理論[decision theory] :: 損失や効用を考慮して行為を選択するための理論。
- MCMC法[Markov chain Monte Carlo method] :: 適切なマルコフ鎖をシミュレーションすることで求めたい分布を漸近的に得る方法。
- ブートストラップ法[bootstrap] :: 標本されたデータから再標本することで、母集団についての情報を得る方法。
- リスク関数[risk function] :: 母数の値と行為を引数にもつ損失の期待値についての関数。
- 事前分布[prior distribution] :: ベイズ統計で事前の知識等から定める仮説や母数についての確率分布。
- 事後分布[posterior distribution] :: ベイズ統計でデータを得た結果導かれる仮説や母数についての確率分布。
- 事象[event] :: 確率空間\((\Outcome, \Field, \mathbb{P})\)が与えられた場合は、\(\Field\)の要素のことを事象と呼ぶ。
- 信用区間[credible interval] :: 確信区間とも訳される。
- 共役事前分布[conjugate prior] :: 対応する事後分布が同じ確率分布族になるような確率分布。推定が扱いやすいために事前分布に採用される。
- 効用関数[utility function] :: 符号を逆転させることで、損失関数と同一視することができる。すなわち、効用関数の最大化は対応する損失関数の最小化にあたる。
- 同時確率[joint probability] :: 複数の確率変数の組からなる確率変数の確率分布。
- 完全加法族[\(\sigma\)-algebra] :: ある集合\(\Outcome\)上の完全加法族とは、完全加法性を満たす\(\Outcome\)の部分集合族。
- 実現値[realization] :: 結果に確率変数をほどこして得られる値。
- 推定値[estimator] :: 母数を推定するため観察された実現値から計算される値、あるいはその導出規則(式やアルゴリズム)。
- 損失関数[loss function] :: 母数と行為にともなう損失を表す関数。
- 最尤法[method of maximum likelihood] ::
- 標本[sample] :: 母集団を表す確率変数の実現値をくり返し得ることに対応する。
- 標本サイズ[sample size] :: 1回の標本で得られる観測の個数。
- 標本分布[sampling distribution] :: 特定の母集団から多数の標本を得た場合にある統計量の確率分布。
- 標本空間[sample space] :: 事象を構成する要素(結果)全体の集合。
- 母数[parameter] :: 母数の値が決まると確率分布が特定される。
- 母集団[population] :: 実験などの対象となるものや事象の集まり。
- 決定規則[decision rule] :: 実現値からどの行為を選ぶかについて定める。つまり、\(\Realization\)から\(\Action\)への関数。
- 確率分布[probability distribution] :: 厳密には確率空間\((\Outcome, \Field, \mathbb{P})\)によって表される。\(\Outcome\)や\(\Field\)が明らかな場合には、\(P\)で簡単に表される。
- 確率変数[random variable] :: 確率空間\((\Outcome, \Field, \mathbb{P})\)からある可測空間\((\Realization, \mathcal{A})\)への可測関数\(X: \Outcome \to \Realization\)。
- 確率空間[probability space] :: 標本空間\(\Outcome\)、\(\Outcome\)上の完全加法族\(\Field\)、および確率関数\(P: \Field \to [0, 1]\)の3つ組\((\Outcome, \Field, \mathbb{P})\)。
- 確率関数[probability function] :: 標本空間\(\Outcome\)と\(\Outcome\)上の完全加法族\(\Field\)について、確率の公理を満たす関数\(P: \Field \to [0, 1]\)を確率関数と呼ぶ。
- 結果[outcome] :: 標本空間の要素。各事象は標本空間の部分集合なので、その要素は結果である。
- 統計量[statistic] :: 標本から計算される量。
- 行為[action] :: 行為空間の要素。
- 超母数[hyperparameter] :: 母数自体が確率変数で表される場合の、その確率分布の母数のこと。

* Footnotes

[fn:1] \doclicenseLongText \doclicenseImage[imagewidth=4em]

[fn:2] \(W\)の\(X\)による逆像: \(X^{-1}(W) \equiv \{\omega \in \Omega: X(\omega) \in W\}.\)

[fn:3] 条件付き確率\(\CondProb{A}{B}\)について考えていることから、\(\Prob{B} \neq 0\)も前提としている。

[fn:4] これは(定理の仮定を満たす)どの確率変数についても成り立つ事実であることに注意。特に、この定理を使って何らかの条件付き確率を求めることは、統計の流儀に関わらず正当である。

[fn:5] Thall PF, Wathen JK, Bekele BN, Champlin RE, Baker LH, Benjamin RS. Hierarchical Bayesian approaches to phase II trials in diseases with multiple subtypes. Statistics in Medicine. 2003;22(5):763-780. doi:10.1002/sim.1399

[fn:6] https://brockk.github.io/trialr/articles/A500-HierarchicalBayesianResponse.html
